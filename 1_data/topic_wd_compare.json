{
  "topics": {
    "International Relations \\ Foreign policy": {
      "questions": {
        "1": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.520102,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.444021,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.666663,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.637354,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.270205,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.34263,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.316378,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.348489,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.39681,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.363294,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.245065,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.282784,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.175008,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.341256,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.373911,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.4081,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.462774,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.389681,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.666662,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.652602,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.553013,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.319119,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.480344,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.375001,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.407241,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.521484,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.414998,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.326731,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.127188,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.221001,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.2533,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.378897,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "6": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.354953,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.388787,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.225097,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.225093,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.31101,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.481017,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.501233,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.444949,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.540238,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.670485,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.517185,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.605217,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.357893,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.449464,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.505577,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.45805,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.439513,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.437317,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.223334,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.225075,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.38398,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.372607,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.360911,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.541369,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.54623,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.971667,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.59475,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.627865,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.475732,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.537803,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.388735,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.542082,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "8": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.523976,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.76729,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.516798,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.514433,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.578178,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.514031,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.507302,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.351262,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.575848,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.735428,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.796604,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.674896,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.324638,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.68892,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.441981,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.33604,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.477734,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.705612,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.516986,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.516342,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.357889,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.508047,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.478562,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.441871,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.557365,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.739714,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.792778,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.563291,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.341626,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.697808,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.376877,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.447367,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "14": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.47985,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.601699,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.21074,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.210739,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.465491,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.454016,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.488368,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.461793,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.484859,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.459941,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.300254,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.404256,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.243007,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.469564,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.655665,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.482941,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.511269,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.566748,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.21074,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.210739,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.647166,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.482868,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.697591,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.4641,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.484822,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.426137,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.209466,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.37361,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.279271,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.308558,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.400557,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.486435,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "15": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.146999,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.109821,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.619528,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.54889,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.060985,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.013169,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.236827,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.027309,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.341561,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.01531,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.068994,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.218975,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.05356,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.337475,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.064128,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.001529,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.011437,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.043315,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.624039,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.624039,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.178824,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.126478,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.276995,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.043615,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.080398,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.199963,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.058325,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.044294,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.108957,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.071073,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.183162,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.008372,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "16": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.943084,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.763005,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.997974,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.997974,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.663416,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.839933,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.90652,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.764876,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.900827,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.881825,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.734542,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.713176,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.622887,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.747826,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.842001,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.760695,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.934768,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.722467,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.997974,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.997974,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.804864,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.74241,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.850276,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.845898,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.899751,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.044179,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.734621,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.865705,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.663235,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.955762,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.87946,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.861696,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "22": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.083757,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.115355,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.350713,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.346646,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.086946,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.14374,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.085656,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.152233,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.104356,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.147575,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.158875,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.205333,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.151882,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.135832,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.050043,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.163469,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.081923,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.095901,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.35071,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.350006,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.053685,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.145578,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.069064,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.136786,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.13346,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.186259,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.110488,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.193448,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.151521,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.134308,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.091601,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.161142,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "23": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.105475,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.105521,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.627339,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.004889,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.100688,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.127705,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.077861,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.084566,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.119061,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.030781,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.104385,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.110133,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.189328,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.047105,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.023236,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.130619,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.053103,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.018883,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.627343,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.349674,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.021032,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.112475,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.045012,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.090013,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.115538,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.079423,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.168069,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.158856,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.213905,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.029823,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.024287,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.097038,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "25": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.023392,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.010799,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.42562,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.425545,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.14547,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.04685,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.170594,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.070704,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.004654,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.033906,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.15649,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.363407,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.072328,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.056833,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.355418,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.05877,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.089286,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.019287,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.425619,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.42155,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.261796,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.016645,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.169717,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.024027,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.175521,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.289545,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.2103,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.373282,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.199179,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.015326,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.071727,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.165827,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "27": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.21829,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.231883,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.235284,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.54277,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.311248,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.121251,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.282444,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.266299,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.240708,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.230308,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.380716,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.457422,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.27833,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.804337,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.236011,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.24539,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.218838,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.304341,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.611367,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.285445,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.299839,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.198785,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.296743,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.304331,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.266573,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.517159,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.505959,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.429482,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.238867,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.620145,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.262755,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.320388,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "42": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.20865,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.219016,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.365773,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.40319,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.235202,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.300911,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.338274,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.245348,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.368626,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.464707,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.304151,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.46701,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.305327,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.311339,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.307089,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.254979,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.226281,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.275047,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.356139,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.395938,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.228188,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.217225,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.181574,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.353482,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.395553,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.709546,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.435326,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.462381,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.377037,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.335101,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.206159,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.35817,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "43": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.163687,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.317393,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.589298,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.513446,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.009525,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.106312,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.016002,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.095994,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.071754,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.083399,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.347319,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.121368,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.364813,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.14307,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.094528,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.10727,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.041171,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.198434,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.589303,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.262649,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.087038,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.025816,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.126516,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.084861,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.020716,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.249099,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.131212,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.099356,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.151451,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.089198,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.17584,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.134656,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "48": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.05119,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.045566,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.383242,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.00581,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.130239,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.105773,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.160545,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.106478,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.002819,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.122822,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.178833,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.451,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.021777,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.143388,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.334292,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.158593,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.044647,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.025817,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.37928,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.295828,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.250292,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.070288,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.064437,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.012519,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.200751,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.307883,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.04993,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.400054,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.013531,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.137022,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.136903,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.157862,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "51": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.175271,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.981063,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.375128,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.375128,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.188001,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.146529,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.191756,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.895431,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.068042,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.756683,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.054244,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.718162,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.043018,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.632276,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.191506,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.773309,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.280926,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.674526,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.375128,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.375128,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.245254,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.005437,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.320938,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.747497,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.192411,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.697406,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.109632,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.806544,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.195567,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.391129,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.237835,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.913294,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "54": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.073047,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.095983,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.370664,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.370709,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.04523,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.138063,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.055604,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.141704,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.081214,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.106171,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.113366,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.0873,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.125922,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.139043,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.091394,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.128912,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.055962,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.076756,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.370709,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.370744,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.020519,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.12625,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.018424,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.121758,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.116941,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.146295,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.088741,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.1499,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.109553,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.090872,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.084889,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.14209,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "66": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.07398,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.997335,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.544381,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.713459,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.094565,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.997806,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.611555,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.922643,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.01386,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.743746,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.520616,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.405791,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.125999,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.168373,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.011845,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.812026,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.982307,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.045499,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.529993,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.979427,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.003188,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.029168,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.89164,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.842513,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.00472,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.152837,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.456697,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.388007,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.181154,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.791484,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.898802,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.849221,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "67": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.307758,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.320615,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.28635,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.3802,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.328608,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.406314,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.46999,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.372657,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.481077,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.587631,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.453292,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.562639,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.196362,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.334242,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.431754,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.359325,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.382025,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.371105,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.060904,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.380524,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.32248,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.299622,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.241051,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.49229,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.4959,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.811418,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.49061,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.499662,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.268622,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.44055,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.423367,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.485392,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "68": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.261489,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.334507,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.427494,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.469606,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.323347,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.290134,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.394321,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.296859,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.385727,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.501679,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.358764,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.465999,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.389351,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.294383,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.441063,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.279164,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.264779,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.297751,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.445609,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.462994,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.253451,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.217442,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.209074,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.395561,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.417217,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.714059,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.393431,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.424612,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.409528,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.373395,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.311359,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.395013,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "69": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.228781,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.265205,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.339166,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.339778,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.329766,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.366874,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.436626,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.340211,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.493475,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.570239,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.456893,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.690836,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.324086,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.297042,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.362966,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.294635,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.308996,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.306175,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.33954,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.339834,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.249693,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.253839,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.242891,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.449086,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.514458,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.832352,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.491088,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.685165,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.375025,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.403067,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.326038,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.396593,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "70": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.30183,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.310236,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.445969,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.155654,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.311552,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.235732,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.758296,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.228147,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.199146,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.918944,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.737445,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.594894,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.92083,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.384146,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.271504,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.052584,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.234336,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.327141,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.442106,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.213046,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.225316,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.283405,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.142619,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.114052,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.232215,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.349819,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.682226,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.616532,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.244555,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.077168,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.061736,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.984921,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "71": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.394196,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.320483,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.52577,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.52604,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.322058,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.410351,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.378034,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.374799,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.543685,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.55422,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.29321,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.495207,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.520253,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.451472,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.398536,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.337021,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.387407,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.404291,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.525597,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.526145,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.330297,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.359973,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.310726,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.442366,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.540262,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.663249,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.302921,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.432701,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.65825,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.400121,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.253852,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.449279,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "72": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.188592,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.212568,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.290553,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.290545,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.199839,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.31374,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.3482,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.311998,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.380656,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.49932,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.54099,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.651414,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.132164,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.255205,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.374185,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.280141,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.263261,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.243212,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.290552,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.290551,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.27501,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.201599,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.161134,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.405922,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.392075,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.879631,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.547669,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.632217,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.218037,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.350157,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.287872,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.38251,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "73": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.356228,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.357062,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.271607,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.271678,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.31565,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.448519,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.486179,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.440536,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.52784,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.642006,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.534125,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.630188,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.355104,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.40997,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.474844,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.425698,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.424491,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.377825,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.271651,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.271682,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.294059,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.35059,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.324871,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.535832,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.540252,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.871309,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.56464,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.628605,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.392519,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.474531,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.384543,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.523002,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "74": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.101736,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.040393,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.559717,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.551139,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.108979,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.033395,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.127644,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.056198,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.101787,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.055986,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.012265,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.074538,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.103772,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.011752,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.069658,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.008064,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.016927,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.012427,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.559717,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.559164,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.2027,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.033629,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.2857,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.030584,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.05099,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.046978,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.099241,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.17549,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.007153,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.147098,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.086426,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.025193,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "75": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.03302,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.074125,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.393476,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.383824,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.040338,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.091303,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.054427,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.103167,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.0023,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.091647,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.018885,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.122366,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.052133,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.057384,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.012967,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.089649,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.029121,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.027631,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.393476,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.337583,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.094752,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.093782,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.141371,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.091477,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.055409,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.172745,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.067056,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.216787,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.088668,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.108145,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.056388,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.074659,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "76": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.96733,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.013505,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.393418,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.228983,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.453906,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.623767,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.682742,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.709006,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.172104,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.412586,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.78778,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.355847,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.770684,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.976556,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.749759,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.846844,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.85775,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.841589,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.393459,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.356149,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.308363,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.710749,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.705342,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.645184,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.261005,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.275993,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.821116,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.214566,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.852602,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.929096,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.910474,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.811308,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "124": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.343534,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.270339,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.346028,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.685826,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.235926,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.163574,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.183765,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.180449,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.253762,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.269345,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.148849,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.220936,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.121333,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.178813,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.244237,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.103971,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.221748,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.236148,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.305755,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.760478,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.163962,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.134194,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.451631,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.112342,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.203072,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.207153,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.244883,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.183639,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.048387,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.064688,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.012343,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.110975,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "125": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.318736,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.337404,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.365123,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.480169,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.354192,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.276576,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.263387,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.250971,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.372943,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.326781,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.295281,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.357393,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.191895,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.301611,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.39345,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.217603,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.297079,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.328949,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.383256,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.23918,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.283641,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.232705,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.466506,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.224603,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.341098,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.297648,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.237402,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.347182,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.131864,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.24488,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.168853,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.220371,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "126": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.148419,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.26965,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.574029,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.574009,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.322002,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.254028,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.200468,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.344607,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.324746,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.152081,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.215397,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.43569,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.202385,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.370622,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.148273,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.343212,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.278576,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.201043,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.574034,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.574023,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.150037,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.25181,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.222006,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.326295,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.516062,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.399777,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.479288,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.325697,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.288397,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.351774,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.383565,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.347354,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "127": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.192519,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.259909,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.584419,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.584412,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.330271,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.253367,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.191951,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.335215,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.369072,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.162178,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.253661,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.400872,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.113804,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.365895,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.146944,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.324333,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.294139,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.209571,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.584424,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.584412,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.164352,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.259549,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.291446,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.308968,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.546818,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.37964,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.483204,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.297884,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.219461,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.310298,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.358026,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.329191,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "129": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.243866,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.30457,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.746381,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.753072,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.216943,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.178408,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.202448,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.181625,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.307211,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.233547,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.203614,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.27556,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.158215,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.233902,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.248329,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.176785,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.204773,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.233014,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.744496,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.753073,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.211019,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.151026,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.349371,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.142865,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.320111,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.212239,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.288946,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.251235,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.096923,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.122101,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.192917,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.160509,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "130": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.272005,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.29155,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.728963,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.734486,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.215831,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.181749,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.207695,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.192391,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.314285,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.232872,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.213264,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.300273,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.161703,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.236203,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.228291,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.174536,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.263111,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.227152,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.659797,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.734744,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.190193,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.153282,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.366575,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.15378,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.355307,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.250895,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.374125,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.246983,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.117442,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.166715,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.229259,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.164741,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "131": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.345206,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.302835,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.910586,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.910325,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.342582,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.215899,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.245233,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.240411,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.316157,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.286839,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.198004,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.27393,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.250232,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.247072,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.331327,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.156566,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.25687,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.264869,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.910586,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.910511,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.268184,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.176607,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.486624,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.168314,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.2712,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.270311,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.116345,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.245277,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.187587,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.140732,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.075505,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.175749,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "133": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.364732,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.2762,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.031568,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.029095,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.27679,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.194555,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.191452,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.1745,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.285997,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.31241,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.25177,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.229018,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.259937,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.229298,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.379776,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.127423,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.214861,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.262798,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.031567,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.027496,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.314766,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.11254,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.50578,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.139397,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.219733,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.225084,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.109048,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.199605,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.202465,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.137077,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.121723,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.140627,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "134": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.709612,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.68389,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.448916,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.448916,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.633677,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.685165,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.580956,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.899773,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.487952,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.484348,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.758664,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.495469,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.129397,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.245154,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.949348,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.866816,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.579923,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.62555,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.448916,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.448916,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.514229,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.680327,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.63773,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.857543,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.646296,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.692097,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.787669,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.466713,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.046655,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.331147,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.866202,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.899576,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "135": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.416362,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.396345,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.753131,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.727887,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.34891,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.36984,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.32512,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.597904,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.204311,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.137644,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.358699,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.08711,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.175905,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.04336,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.639403,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.566296,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.298318,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.306459,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.43638,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.257196,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.221997,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.34584,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.374659,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.543065,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.344952,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.374874,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.502523,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.249325,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.046038,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.155804,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.587534,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.607751,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "136": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.047374,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.188892,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.160546,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.160546,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.089328,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.152907,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.105756,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.20052,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.182185,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.228974,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.194937,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.211489,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.40321,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.345127,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.181356,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.237646,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.130032,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.111774,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.160546,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.160546,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.204362,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.191794,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.070259,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.218401,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.100769,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.15769,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.150396,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.180478,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.43045,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.32919,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.291765,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.199423,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "137": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.275629,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.219328,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.419624,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.419624,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.315385,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.276743,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.347999,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.104118,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.445041,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.506494,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.246481,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.695348,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.731352,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.632527,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.087415,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.13543,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.398734,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.388227,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.419624,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.419624,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.462428,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.273651,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.286528,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.129972,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.302821,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.299748,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.078137,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.269455,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.715697,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.576375,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.13867,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.114521,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "138": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.316309,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.375159,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.804593,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.49419,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.37909,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.368445,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.301877,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.155158,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.498572,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.606736,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.267075,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.712112,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.65794,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.713873,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.117052,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.186596,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.464894,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.477466,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.456678,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.492555,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.506116,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.345364,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.258927,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.196202,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.367272,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.385871,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.128155,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.433821,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.653482,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.627628,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.129726,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.150051,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "139": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.221131,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.271959,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.67562,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.642921,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.257269,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.319273,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.224957,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.084488,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.410367,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.503518,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.295312,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.357341,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.275245,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.63151,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.157576,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.096469,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.404599,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.347849,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.67562,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.573623,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.396519,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.289895,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.205019,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.137616,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.287077,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.292946,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.108627,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.273587,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.259097,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.540275,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.021019,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.078563,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "140": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.129945,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.119166,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.954436,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.014551,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.111356,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.132664,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.130545,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.333727,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.062439,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.126543,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.121347,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.218587,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.293517,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.181835,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.376918,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.302416,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.045706,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.063365,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.000487,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.014552,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.091225,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.140413,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.13654,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.297041,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.086789,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.116759,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.340157,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.143042,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.208673,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.14233,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.278038,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.346571,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "141": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.40412,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.267405,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.052607,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.147946,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.499431,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.257097,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.335562,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.252612,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.377171,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.259477,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.251991,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.155764,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.278112,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.393285,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.426342,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.209312,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.360547,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.305289,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.143889,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.14794,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.307437,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.273435,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.4488,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.218159,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.347668,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.278767,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.337924,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.261579,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.278955,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.303207,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.292702,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.247597,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "142": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.156499,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.138956,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.226847,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.226841,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.229994,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.075937,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.061291,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.113314,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.285465,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.320729,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.224452,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.232087,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.401959,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.486465,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.111698,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.092568,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.184881,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.220289,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.226847,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.226846,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.207281,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.109134,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.184675,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.053465,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.15174,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.0532,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.100216,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.129516,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.393223,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.407671,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.198418,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.105391,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "143": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.223642,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.296515,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.343126,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.34311,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.217087,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.225341,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.186432,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.013383,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.346491,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.432787,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.250555,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.514032,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.244837,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.616034,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.11948,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.045123,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.335694,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.346166,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.343127,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.343124,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.345121,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.254187,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.181762,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.035487,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.256128,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.200226,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.281331,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.23296,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.454166,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.536937,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.044813,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.015753,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "144": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.235693,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.332152,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.366048,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.26168,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.279607,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.258828,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.217525,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.054541,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.334964,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.485229,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.244213,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.468518,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.288691,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.594332,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.24354,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.059949,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.363502,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.332495,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.353155,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.34385,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.377962,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.271664,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.248346,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.048559,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.275208,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.206871,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.225042,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.279874,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.439621,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.543925,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.04171,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.054273,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "149": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.544379,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.363276,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.895964,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.982086,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.294143,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.4395,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.604325,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.434817,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.692299,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.572382,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.172377,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.390707,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.577968,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.540034,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.311375,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.33748,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.528004,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.380931,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.895664,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.982803,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.518697,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.433788,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.757028,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.428111,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.446325,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.5262,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.278998,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.431296,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.725331,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.474518,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.271746,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.38035,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        }
      },
      "summary": {
        "by_model_language_variant": {
          "no_refusal": [
            {
              "model": "gpt-4o-mini",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.8272872608695652,
              "n_questions_counted": 46
            },
            {
              "model": "gpt-4o-mini",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.8005721086956522,
              "n_questions_counted": 46
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.4122259565217391,
              "n_questions_counted": 46
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.4059827173913043,
              "n_questions_counted": 46
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.39829463043478264,
              "n_questions_counted": 46
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.37987965217391306,
              "n_questions_counted": 46
            },
            {
              "model": "c4ai-command-r7b",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.35671165217391304,
              "n_questions_counted": 46
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.35608176086956517,
              "n_questions_counted": 46
            },
            {
              "model": "zephyr-7b-beta",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.3479998043478261,
              "n_questions_counted": 46
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.3425691304347826,
              "n_questions_counted": 46
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.3343533913043478,
              "n_questions_counted": 46
            },
            {
              "model": "c4ai-command-r7b",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.33035597826086954,
              "n_questions_counted": 46
            },
            {
              "model": "zephyr-7b-beta",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.32639884782608697,
              "n_questions_counted": 46
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.31176589130434784,
              "n_questions_counted": 46
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.30852439130434783,
              "n_questions_counted": 46
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.30734984782608693,
              "n_questions_counted": 46
            }
          ],
          "with_refusal": [
            {
              "model": "gpt-4o-mini",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.8333214130434783,
              "n_questions_counted": 46
            },
            {
              "model": "gpt-4o-mini",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.827094,
              "n_questions_counted": 46
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.4279161956521739,
              "n_questions_counted": 46
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.3800917391304348,
              "n_questions_counted": 46
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.37474545652173913,
              "n_questions_counted": 46
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.3616741956521739,
              "n_questions_counted": 46
            },
            {
              "model": "zephyr-7b-beta",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.35655965217391306,
              "n_questions_counted": 46
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.34834206521739125,
              "n_questions_counted": 46
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.3446133913043478,
              "n_questions_counted": 46
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.34287347826086956,
              "n_questions_counted": 46
            },
            {
              "model": "c4ai-command-r7b",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.34083004347826085,
              "n_questions_counted": 46
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.3344571956521739,
              "n_questions_counted": 46
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.33231841304347826,
              "n_questions_counted": 46
            },
            {
              "model": "c4ai-command-r7b",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.3305874565217391,
              "n_questions_counted": 46
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.33008056521739126,
              "n_questions_counted": 46
            },
            {
              "model": "zephyr-7b-beta",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.2930321304347826,
              "n_questions_counted": 46
            }
          ]
        }
      }
    },
    "Israel-Palestine": {
      "questions": {
        "32": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.346771,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.673981,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.970064,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.910745,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.332959,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.477039,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.426431,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.553509,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.412986,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.507301,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.411289,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.505666,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.338303,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.496447,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.331273,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.543275,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.363216,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.67082,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.970071,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.910748,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.374614,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.493881,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.318984,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.514562,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.399102,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.516179,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.367682,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.519156,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.308956,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.5412,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.320726,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.519751,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "33": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.646747,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.252162,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 2.343653,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 2.343747,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.055649,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.384824,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.774329,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.739147,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.015347,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.873969,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.343074,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.358009,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.819777,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.876635,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.092784,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.647989,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.820476,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.264654,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 2.343544,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 2.343747,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.311421,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.543629,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.848815,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.344442,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.793095,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.257223,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.282214,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.442671,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.969754,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.748173,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.203176,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.431338,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "34": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.484135,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.364612,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.595012,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.19771,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.235802,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.327986,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.276068,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.222294,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.386491,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.537562,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.293117,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.219032,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.437562,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.468148,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.201814,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.280772,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.439907,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.385058,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.690164,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 2.166564,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.262235,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.300582,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.302879,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.248541,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.252232,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.271724,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.383985,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.288683,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.592976,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.510446,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.150222,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.234348,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "35": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.136717,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.799406,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.854177,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.693104,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.088592,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.660747,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.103423,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.651638,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.095045,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.723504,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.124441,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.439789,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.081779,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.446068,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.100346,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.577833,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.108609,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.890156,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.291832,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.694168,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.12306,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.640018,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.183155,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.585111,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.097134,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.702148,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.129947,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.488782,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.10515,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.402334,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.139271,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.655992,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "84": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.13888,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.779467,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.735925,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.735318,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.070967,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.913819,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.339582,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.891566,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.127291,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.718626,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.51573,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.346322,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.234245,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.471093,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.315762,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.01965,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.230207,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.872519,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.735925,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.733048,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.152239,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.856077,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.30534,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.982023,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.20017,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.836741,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.482847,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.224852,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.237196,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.542869,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.287673,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.904318,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "85": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.422747,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.335396,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.194805,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.143782,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.561446,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.497532,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.402474,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.510627,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.540051,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.279782,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.052257,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.123352,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.365598,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.116868,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.449228,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.613794,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.589663,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.351862,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.194805,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.180757,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.444454,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.473868,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.365493,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.533993,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.592466,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.435078,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.971308,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.09934,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.349301,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.113393,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.755124,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.492249,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "86": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.617241,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.300998,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.788178,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.821708,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.558976,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.411332,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.741142,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.404423,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.474975,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.353722,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.173199,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.15426,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.543093,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.285811,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.820801,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.515888,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.482174,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.368557,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.539641,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.097392,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.585657,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.345399,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.723701,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.463597,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.415241,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.310844,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.190973,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.415999,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.436393,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.24996,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.803102,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.398525,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "87": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.404629,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.528675,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.412357,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.157804,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.309443,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.671536,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.440018,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.641934,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.254271,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.340729,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.374563,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.361925,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.147232,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.272485,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.450474,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.770979,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.264739,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.598295,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.576079,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.220944,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.35412,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.623682,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.409268,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.713174,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.213842,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.58722,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.288977,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.183421,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.172888,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.361063,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.165721,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.639914,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "88": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.367751,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.492052,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.656428,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 2.260394,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.428055,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.647296,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.488312,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.514012,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.204345,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.541143,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.375771,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.758776,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.271752,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.735687,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.4883,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.631284,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.446321,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.40509,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.679621,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 2.187966,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.398687,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.561493,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.32792,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.594607,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.292662,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.734083,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.491192,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.711891,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.29071,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.645035,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.532927,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.586601,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "90": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.859379,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.533352,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.664354,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.664357,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.557963,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.461711,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.572215,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.483604,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.684239,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.519935,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.935845,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.421567,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.26998,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.39392,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.701043,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.475713,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.673961,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.441783,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.653054,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.666977,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.642624,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.48254,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.651687,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.451308,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.486033,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.550629,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.620514,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.490438,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.274677,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.319899,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.455357,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.43301,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "91": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.785611,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.466621,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.388818,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.561708,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.530903,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.394539,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.466026,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.386908,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.574806,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.418595,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.98244,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.343598,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.236326,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.276143,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.639412,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.349665,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.63703,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.395209,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.483293,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.609388,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.563025,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.421001,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.568053,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.362065,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.376128,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.469538,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.721195,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.428029,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.22913,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.252516,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.419111,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.343156,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "92": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.854399,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.531857,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.627306,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.624226,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.576717,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.481502,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.563146,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.460105,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.699214,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.494122,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.921596,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.451905,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.23655,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.364886,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.718849,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.437253,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.690613,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.447636,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.629718,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.629673,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.629501,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.50559,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.640161,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.433213,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.51193,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.520085,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.666226,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.459889,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.263189,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.265283,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.643737,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.437862,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "93": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.862014,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.435411,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.556457,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.441293,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.680995,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.447328,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.565724,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.432164,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.668326,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.417451,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.149575,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.420927,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.25381,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.231172,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.769666,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.49522,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.800643,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.34939,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.559024,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.546377,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.612793,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.518044,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.533025,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.438852,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.448881,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.434149,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.916463,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.434015,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.25228,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.264491,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.475055,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.434544,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "94": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.656181,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.437568,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.891013,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.892163,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.449028,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.372676,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.370231,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.355481,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.462731,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.397437,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.783656,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.348872,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.283208,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.209969,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.542943,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.345508,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.541538,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.315573,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.895064,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.882151,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.421376,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.365534,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.579997,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.335565,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.289437,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.448508,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.570728,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.415712,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.353386,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.155814,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.465072,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.328824,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "95": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.088936,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.025231,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.461934,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.461934,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.026062,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.00734,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.109313,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.031801,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.137274,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.056356,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.025146,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.008368,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.09396,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.046319,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.017046,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.049428,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.07844,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.006526,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.461934,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.461934,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.133355,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.012195,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.070037,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.060411,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.018215,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.089679,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.09073,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.080327,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.149092,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.020493,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.024549,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.059112,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "104": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.524463,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.38475,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.445398,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.17257,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.446239,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.225241,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.288455,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.305887,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.239565,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.265506,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.111172,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.455332,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.167204,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.067924,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.286892,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.298687,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.456185,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.415929,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.364297,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.260256,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.49314,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.243528,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.238216,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.238058,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.315153,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.454105,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.243964,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.326826,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.293927,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.324308,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.144481,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.181051,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "105": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.857847,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.824113,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.505832,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.545786,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.77085,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.559209,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.152702,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.616986,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.589483,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.42176,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.084072,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.305477,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.373929,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.366383,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.63526,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.615384,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.82649,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.619918,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.428739,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.588309,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.975741,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.615402,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.645907,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.52581,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.573657,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.36511,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.117023,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.182087,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.760476,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.102234,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.572916,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.414011,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "106": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.441465,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.345684,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.457792,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.457791,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.306115,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.121483,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.496948,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.156479,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.084406,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.71957,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.517845,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.311758,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.420575,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.060281,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.254719,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.187287,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.332089,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.284171,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.457792,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.457791,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.457807,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.170963,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.158048,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.077247,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.125917,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.430145,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.548583,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.45238,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.114161,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.32262,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.127431,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.991593,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "107": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.226863,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.281423,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.089231,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.051592,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.16277,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.395803,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.575444,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.337571,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.35042,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.539359,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.447543,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.831166,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.48449,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.345937,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.339501,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.338761,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.277734,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.288884,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.934609,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.099925,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.110149,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.304401,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.244702,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.422152,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.349885,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.918808,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.655323,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.76243,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.197636,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.761267,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.468122,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.40759,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "108": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.381039,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.291702,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.902352,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.95673,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.204759,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.327579,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.334462,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.252285,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.316896,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.480258,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.345618,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.748555,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.084612,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.349369,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.156871,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.280153,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.333545,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.233947,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.748232,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.245656,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.282563,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.230097,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.191582,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.331078,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.363125,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.660026,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.398991,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.578583,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.257623,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.462362,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.153893,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.319726,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "109": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.481426,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.128246,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.660869,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.665162,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.413756,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.228634,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.285832,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.97086,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.493427,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.259821,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.666404,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.918229,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.469575,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.010179,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.386889,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.946609,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.414984,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.859413,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.289608,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.804874,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.452201,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.291594,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.383772,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.123214,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.501265,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.403084,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.651916,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.774932,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.466592,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.213724,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.346722,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.056404,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "110": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.12794,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.261228,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.83155,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.698318,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.232377,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.774251,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.548747,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.056327,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.450173,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.912613,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.17966,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.919954,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.678943,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.847242,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.496719,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.019384,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.218125,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.474135,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.875536,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.713068,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.461477,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.701163,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.715965,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.809979,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.139739,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.567678,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.28206,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.760888,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.938153,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.831414,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.662653,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.869197,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "111": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.737914,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.654815,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.710985,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.353774,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.676511,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.40262,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.331227,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.465039,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.454007,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.399911,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.739867,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.621493,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.308106,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.441669,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.507193,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.471485,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.627827,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.55602,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.699532,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.310447,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.411234,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.383851,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.336301,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.483133,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.80163,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.60152,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.731538,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.636437,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.117114,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.419641,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.309377,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.428089,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "113": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.308103,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.366181,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.164954,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.949546,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.308715,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.713874,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.237668,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.481206,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.185776,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.158563,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.466593,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.296299,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.101075,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.465292,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.425529,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.530412,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.283538,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.28484,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.164972,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.949546,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.247753,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.760175,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.117393,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.452769,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.374007,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.840563,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.370356,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.451856,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.099997,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.207095,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.346488,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.492104,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "114": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.131854,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.350974,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.373175,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.082391,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.178381,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.465386,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.136637,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.629613,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.263238,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.629246,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.235194,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.839978,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.271588,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.410507,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.151,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.602657,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.174153,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.511156,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.372027,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.041784,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.219109,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.320357,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.291621,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.515115,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.162821,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.231804,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.213505,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.614543,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.351225,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.511587,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.158141,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.445568,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "115": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.254291,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.560173,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.255061,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.093091,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.303349,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.648454,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.296911,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.852382,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.392281,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.80924,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.352072,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.072974,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.228689,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.786497,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.27501,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.799036,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.314294,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.677901,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.255061,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.093096,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.284701,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.56715,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.470258,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.758261,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.290974,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.557325,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.347071,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.920433,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.236609,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.816573,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.295023,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.662337,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "116": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.694179,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.64447,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.479232,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.383766,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.625661,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.634728,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.835897,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.854672,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.007038,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.944151,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.664741,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.094041,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.369827,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.786918,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.421145,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.762581,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.650574,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.746091,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.55678,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.405175,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.892905,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.613532,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.520091,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.852137,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.770058,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.779783,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.592478,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.170665,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.077022,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.609612,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.56384,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.776393,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "117": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.243593,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.323529,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.06947,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.432024,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.189333,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.145144,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.324167,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.311051,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.223735,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.110243,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.215486,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.329357,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.498221,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.598115,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.228916,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.126711,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.277645,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.24693,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.069481,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.432024,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.259789,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.209393,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.48243,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.169338,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.156432,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.260312,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.050643,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.288899,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.738419,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.41527,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.313637,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.092022,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "120": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.265224,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.287639,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.21255,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.573887,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.321275,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.289938,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.077303,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.348613,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.273079,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.269246,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.180851,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.235464,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.183795,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.206411,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.353462,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.402947,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.272362,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.309393,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.21255,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.573887,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.242362,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.370385,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.070546,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.336564,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.300267,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.30179,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.15234,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.515762,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.14963,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.20612,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.315043,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.302753,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "121": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.221534,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.23033,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.254813,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.633232,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.289224,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.231026,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.062159,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.319574,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.240029,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.240021,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.168807,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.221506,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.150348,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.18179,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.302215,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.361922,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.245412,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.261031,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.254812,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.633232,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.222283,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.302368,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.079385,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.295415,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.261406,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.264142,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.172649,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.482953,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.132615,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.191004,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.255769,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.265053,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "128": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.359769,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.247797,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.510202,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.928967,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.213277,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.201988,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.186437,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.174493,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.310732,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.233075,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.205197,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.262313,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.169906,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.265047,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.314723,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.116594,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.31177,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.243641,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.507971,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.928376,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.221942,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.147179,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.428316,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.1294,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.23645,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.19733,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.30816,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.242397,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.125386,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.194516,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.024656,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.11688,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "145": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.517227,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.376003,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.559001,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.884923,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.420226,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.407118,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.552873,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.496047,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.501015,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.783547,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.100235,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.450337,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.337168,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.677234,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.512322,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.427554,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.589485,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.508662,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.539465,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.829059,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.543479,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.403133,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.521929,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.435782,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.433531,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.547782,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.108444,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.260758,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.458059,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.641605,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.453676,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.480826,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "146": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.821773,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.63951,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.584173,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.840755,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.660754,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.678427,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.714783,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.752219,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.737253,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.067859,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.193722,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.75483,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.580309,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.995278,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.79861,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.683513,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.92218,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.759354,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.583198,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.80991,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.880246,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.672896,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.802188,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.71212,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.668707,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.810677,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.206377,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.596867,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.690909,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.847154,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.727442,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.760246,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        }
      },
      "summary": {
        "by_model_language_variant": {
          "no_refusal": [
            {
              "model": "gpt-4o-mini",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 1.1701302424242424,
              "n_questions_counted": 33
            },
            {
              "model": "gpt-4o-mini",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.8244582121212122,
              "n_questions_counted": 33
            },
            {
              "model": "zephyr-7b-beta",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.5674523636363636,
              "n_questions_counted": 33
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.5654702121212121,
              "n_questions_counted": 33
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.5583097878787879,
              "n_questions_counted": 33
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.533579090909091,
              "n_questions_counted": 33
            },
            {
              "model": "c4ai-command-r7b",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.5198592727272727,
              "n_questions_counted": 33
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.5130736666666667,
              "n_questions_counted": 33
            },
            {
              "model": "zephyr-7b-beta",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.4995974848484848,
              "n_questions_counted": 33
            },
            {
              "model": "c4ai-command-r7b",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.4929891515151515,
              "n_questions_counted": 33
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.47132496969696974,
              "n_questions_counted": 33
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.44999833333333333,
              "n_questions_counted": 33
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.4344478181818182,
              "n_questions_counted": 33
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.429913,
              "n_questions_counted": 33
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.3962753333333333,
              "n_questions_counted": 33
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.34822833333333336,
              "n_questions_counted": 33
            }
          ],
          "with_refusal": [
            {
              "model": "gpt-4o-mini",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 1.1972196666666666,
              "n_questions_counted": 33
            },
            {
              "model": "gpt-4o-mini",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.788437303030303,
              "n_questions_counted": 33
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.5562367272727273,
              "n_questions_counted": 33
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.5372435151515151,
              "n_questions_counted": 33
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.5288212121212121,
              "n_questions_counted": 33
            },
            {
              "model": "c4ai-command-r7b",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.5165013333333333,
              "n_questions_counted": 33
            },
            {
              "model": "zephyr-7b-beta",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.5139814242424242,
              "n_questions_counted": 33
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.5061485151515152,
              "n_questions_counted": 33
            },
            {
              "model": "c4ai-command-r7b",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.4756342121212121,
              "n_questions_counted": 33
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.4747891515151515,
              "n_questions_counted": 33
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.47052015151515153,
              "n_questions_counted": 33
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.46882045454545457,
              "n_questions_counted": 33
            },
            {
              "model": "zephyr-7b-beta",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.4569737272727273,
              "n_questions_counted": 33
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.40383036363636365,
              "n_questions_counted": 33
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.4003512727272727,
              "n_questions_counted": 33
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.3997160909090909,
              "n_questions_counted": 33
            }
          ]
        }
      }
    },
    "Israel-USA": {
      "questions": {
        "52": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.638647,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.687096,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.144375,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.144806,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.576453,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.587798,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.504465,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.535208,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.64645,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.823698,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.678237,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.971168,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.53585,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.67115,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.418652,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.446326,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.588105,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.670349,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.144602,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.144806,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.596001,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.520436,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.481017,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.800608,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.692724,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.98923,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.591252,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.773797,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.575684,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.711012,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.33205,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.607134,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "83": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.380518,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.525691,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.674054,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.198255,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.214364,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.21091,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.242946,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.203777,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.298626,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.69778,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.214054,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.107237,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.199231,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.479045,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.339778,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.220095,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.351453,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.777315,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.674337,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.753697,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.203069,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.291204,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.433309,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.237231,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.288796,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.252883,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.239805,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.065687,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.571407,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.549004,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.339627,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.247858,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "89": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.223544,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.94282,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.953673,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.956697,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.209421,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.653901,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.116778,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.712006,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.132776,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.622623,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.386596,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.422198,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.197943,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.332954,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.208375,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.64307,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.224332,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.905448,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.956359,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.956697,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.301137,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.696852,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.401383,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.628183,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.139827,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.449722,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.210342,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.415278,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.293847,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.395796,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.139544,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.654076,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "99": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.549508,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.83945,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.796315,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.008187,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.623451,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.018237,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.43501,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.051217,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.552743,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.968354,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.649095,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.985668,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.141429,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.675763,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.617229,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.077599,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.437882,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.883131,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.796315,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.008188,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.713317,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.002535,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.171345,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.054051,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.699438,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.226608,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.623304,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.938111,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.162042,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.683384,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.731626,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.055665,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "112": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.08071,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.273595,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.51134,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 2.469223,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.130655,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.188253,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.05268,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.300909,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.153782,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.581961,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.199974,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.704952,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.354124,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.782494,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.116228,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.279871,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.114474,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.322941,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.511519,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 2.469223,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.116339,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.318835,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.330657,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.205786,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.035536,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.274541,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.333979,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.50071,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.376281,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.61067,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.060287,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.167731,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "118": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.289991,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.392014,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.177992,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.498986,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.360402,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.374244,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.112389,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.364818,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.298206,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.297585,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.227022,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.262601,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.229289,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.242667,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.401841,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.411786,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.299927,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.32268,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.177992,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.498986,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.234059,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.447165,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.055246,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.361882,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.338475,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.383888,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.211521,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.448922,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.112546,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.235658,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.366807,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.33402,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "119": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.185442,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.222387,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.29078,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.640324,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.250288,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.228535,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.049807,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.269515,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.20657,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.195674,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.136665,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.214136,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.122774,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.129737,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.274154,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.30595,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.199282,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.215203,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.29078,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.640324,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.163965,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.295995,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.063286,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.248723,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.232633,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.220557,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.170898,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.414824,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.09511,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.139465,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.22931,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.222399,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "132": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.491152,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.396198,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.095785,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.095816,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.33912,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.240826,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.209454,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.158404,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.256926,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.38203,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.266955,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.159259,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.266087,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.222139,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.366822,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.140115,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.266786,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.301987,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.095617,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.095816,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.379307,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.221253,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.555849,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.175263,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.187145,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.216234,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.083544,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.178883,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.19849,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.225236,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.136005,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.201579,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "148": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.334809,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.349006,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.303979,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.771101,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.291187,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.311877,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.314426,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.283201,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.34165,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.406758,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.433432,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.441926,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.265424,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.655367,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.478036,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.35295,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.351848,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.366696,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.375923,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.92034,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.25695,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.373442,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.262981,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.285862,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.276664,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.475755,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.471548,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.497971,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.286952,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.518003,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.325011,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.270629,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "150": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.257917,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.194978,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.617656,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.712596,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.641757,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.328384,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.531842,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.347834,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.334447,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.270247,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.914184,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.500898,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.444785,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.480482,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.352271,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.479363,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.258716,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.258675,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.677244,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.709401,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.393593,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.269627,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.548627,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.301956,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.394423,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.677348,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.766172,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.33746,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.370679,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.449709,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.27621,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.347146,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        }
      },
      "summary": {
        "by_model_language_variant": {
          "no_refusal": [
            {
              "model": "gpt-4o-mini",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 1.1495991,
              "n_questions_counted": 10
            },
            {
              "model": "gpt-4o-mini",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.9565949,
              "n_questions_counted": 10
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.524671,
              "n_questions_counted": 10
            },
            {
              "model": "c4ai-command-r7b",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.4823235,
              "n_questions_counted": 10
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.47700430000000005,
              "n_questions_counted": 10
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.4671798,
              "n_questions_counted": 10
            },
            {
              "model": "zephyr-7b-beta",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.4357125,
              "n_questions_counted": 10
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.4226889,
              "n_questions_counted": 10
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.4142965,
              "n_questions_counted": 10
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.41062139999999997,
              "n_questions_counted": 10
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.36370979999999997,
              "n_questions_counted": 10
            },
            {
              "model": "zephyr-7b-beta",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.3573386,
              "n_questions_counted": 10
            },
            {
              "model": "c4ai-command-r7b",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.34322379999999997,
              "n_questions_counted": 10
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.3222176,
              "n_questions_counted": 10
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.2756936,
              "n_questions_counted": 10
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.2569797,
              "n_questions_counted": 10
            }
          ],
          "with_refusal": [
            {
              "model": "gpt-4o-mini",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 1.2197478,
              "n_questions_counted": 10
            },
            {
              "model": "gpt-4o-mini",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.9700688,
              "n_questions_counted": 10
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.5166766,
              "n_questions_counted": 10
            },
            {
              "model": "c4ai-command-r7b",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.5024425,
              "n_questions_counted": 10
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.45716429999999997,
              "n_questions_counted": 10
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.45179369999999996,
              "n_questions_counted": 10
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.44373440000000003,
              "n_questions_counted": 10
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.4299545,
              "n_questions_counted": 10
            },
            {
              "model": "zephyr-7b-beta",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.4108237,
              "n_questions_counted": 10
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.37023649999999997,
              "n_questions_counted": 10
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.3357737,
              "n_questions_counted": 10
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.33037,
              "n_questions_counted": 10
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.3285661,
              "n_questions_counted": 10
            },
            {
              "model": "c4ai-command-r7b",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.30928049999999996,
              "n_questions_counted": 10
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.3043038,
              "n_questions_counted": 10
            },
            {
              "model": "zephyr-7b-beta",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.2936477,
              "n_questions_counted": 10
            }
          ]
        }
      }
    },
    "Leaders": {
      "questions": {
        "3": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.124379,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.762941,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.668507,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.665917,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.918769,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.818577,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.927905,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.864908,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.822257,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.654955,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.890727,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.851982,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.286689,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.601379,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.227788,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.963732,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.057634,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.688454,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.669097,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.666745,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.838142,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.848229,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.552135,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.908409,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.98227,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.931368,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.911042,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.487469,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.551722,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.74493,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.186888,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.991091,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "9": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.270724,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.105527,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.715617,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.8111,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.243726,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.222081,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.28852,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.23863,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.195589,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.120085,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.159934,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.205713,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.269152,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.128546,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.37774,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.225929,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.225503,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.107038,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.669313,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.0822,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.186851,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.254664,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.241731,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.280721,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.210554,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.16273,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.290051,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.201034,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.197761,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.115566,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.268944,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.316061,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "12": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.560197,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.337471,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.252071,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.236903,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.414869,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.361373,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.523737,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.377687,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.491678,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.349801,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.368055,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.277221,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.34563,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.241417,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.403495,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.314665,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.441771,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.313889,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.251969,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.25714,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.380333,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.336079,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.428696,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.388489,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.505875,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.373826,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.483862,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.267317,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.319479,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.350323,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.490008,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.389778,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "17": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.29703,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.016381,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.243182,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.953857,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.25363,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.819444,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.196432,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.697536,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.352032,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.871532,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.217619,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.083048,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.657063,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.675358,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.217105,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.782739,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.322388,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.230889,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.212401,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.953928,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.260329,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.813872,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.239314,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.799869,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.35232,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.842067,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.394365,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.012671,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.547592,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.816122,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.375904,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.877216,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "18": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.82047,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.511178,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.605701,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.811506,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.844533,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.706758,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.631593,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.748945,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.921947,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.642594,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.605239,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.556158,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.527802,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.043769,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.746215,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.71986,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.919009,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.759968,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.605707,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.554103,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.903405,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.733035,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.818581,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.620735,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.119563,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.87587,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.465919,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.513945,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.778828,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.775563,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.578732,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.643236,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "19": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.228382,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.153206,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.657267,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.353792,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.188144,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.263856,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.135096,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.300346,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.364176,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.196553,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.257545,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.678702,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.289594,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.563867,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.062835,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.233794,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.231115,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.348826,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.646427,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.968593,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.215045,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.262805,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.38558,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.142057,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.457209,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.807476,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.253562,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.381637,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.306697,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.273826,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.194099,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.104949,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "77": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.251055,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.026444,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.650061,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.603469,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.88681,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.906965,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.908166,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.85699,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.021095,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.059044,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.882042,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.780651,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.17499,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.139443,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.287249,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.886365,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.168921,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.055563,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.643159,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.463398,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.111463,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.827212,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.310043,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.809586,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.915315,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.020083,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.629634,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.777647,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.170919,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.864739,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.807245,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.775076,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "78": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.510639,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.267893,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.329915,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.329497,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.126386,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.203992,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.963042,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.120733,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.266039,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.313538,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.104323,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.98511,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.903693,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.355374,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.522916,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.135385,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.440451,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.292941,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.269842,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.329219,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.354272,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.110446,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.547441,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.068305,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.160821,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.273434,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.817738,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.049569,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.149312,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.150844,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.038586,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.028951,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "79": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.612258,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.322763,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.752464,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.70354,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.327783,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.264338,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.416459,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.264829,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.432002,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.380017,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.422903,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.212477,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.364504,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.437775,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.52218,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.200461,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.452739,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.301427,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.754,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.688361,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.37779,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.272487,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.591166,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.271712,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.40258,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.267992,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.268461,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.17771,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.403299,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.332018,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.519025,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.2885,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "80": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.426885,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.201048,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.404716,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.396571,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.367194,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.240177,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.392778,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.24178,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.354108,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.236473,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.268041,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.261612,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.224045,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.152323,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.428202,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.173795,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.332387,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.168839,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.404692,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.404669,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.226564,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.226453,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.447022,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.251761,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.386066,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.242894,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.24875,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.218095,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.198084,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.243316,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.375434,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.268049,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "81": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.745937,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.416864,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.859112,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.207863,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.379076,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.388739,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.515187,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.357074,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.556281,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.504854,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.493447,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.329479,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.443065,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.516138,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.664112,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.332512,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.591006,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.40747,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.796959,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.497003,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.503687,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.357371,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.740119,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.330736,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.513593,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.385092,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.240641,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.307555,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.487927,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.438981,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.433041,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.30261,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "82": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.573488,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.24878,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.848728,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.461864,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.235938,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.200373,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.311239,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.18962,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.400823,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.360607,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.339125,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.128955,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.226621,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.286854,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.652977,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.196035,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.454522,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.223192,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.764877,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.226239,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.383895,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.18136,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.655533,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.161671,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.35621,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.297302,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.173118,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.110722,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.299147,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.179574,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.32545,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.160661,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "100": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.335685,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.756856,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.580402,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.47236,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.191352,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.844235,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.06941,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.800209,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.970024,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.667945,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.749774,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.64504,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.333006,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.636329,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.119265,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.886518,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.49886,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.710124,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.580402,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.47236,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.105959,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.833221,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.966983,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.804683,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.90482,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.757691,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.720038,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.631509,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.235368,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.638353,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.110938,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.779282,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "147": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.435005,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.705019,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.309827,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.437797,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.487645,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.764674,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.273469,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.582087,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.377166,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.874627,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.301211,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.620945,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.324328,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.863503,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.424298,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.525573,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.345809,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.71302,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.31229,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.437665,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.370374,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.647717,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.357934,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.60914,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.350062,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.15326,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.314226,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.717929,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.389011,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.727074,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.23651,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.571877,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        }
      },
      "summary": {
        "by_model_language_variant": {
          "no_refusal": [
            {
              "model": "gpt-4o-mini",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.9604311428571428,
              "n_questions_counted": 14
            },
            {
              "model": "gpt-4o-mini",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.8483978571428572,
              "n_questions_counted": 14
            },
            {
              "model": "c4ai-command-r7b",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.7280095714285714,
              "n_questions_counted": 14
            },
            {
              "model": "zephyr-7b-beta",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.6897412142857143,
              "n_questions_counted": 14
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.6172910714285714,
              "n_questions_counted": 14
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.6089440714285714,
              "n_questions_counted": 14
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.5880446428571429,
              "n_questions_counted": 14
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.5718272857142858,
              "n_questions_counted": 14
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.5618467857142857,
              "n_questions_counted": 14
            },
            {
              "model": "c4ai-command-r7b",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.5594550714285714,
              "n_questions_counted": 14
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.5458124285714285,
              "n_questions_counted": 14
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.5440780714285715,
              "n_questions_counted": 14
            },
            {
              "model": "zephyr-7b-beta",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.5412402142857143,
              "n_questions_counted": 14
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.5395023571428571,
              "n_questions_counted": 14
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.5042846428571429,
              "n_questions_counted": 14
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.455013,
              "n_questions_counted": 14
            }
          ],
          "with_refusal": [
            {
              "model": "gpt-4o-mini",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.9286873571428572,
              "n_questions_counted": 14
            },
            {
              "model": "gpt-4o-mini",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.8272239285714286,
              "n_questions_counted": 14
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.7422203571428572,
              "n_questions_counted": 14
            },
            {
              "model": "c4ai-command-r7b",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.6772939285714286,
              "n_questions_counted": 14
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.6630198571428572,
              "n_questions_counted": 14
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.6155184285714286,
              "n_questions_counted": 14
            },
            {
              "model": "c4ai-command-r7b",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.5944028571428571,
              "n_questions_counted": 14
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.5870077857142857,
              "n_questions_counted": 14
            },
            {
              "model": "zephyr-7b-beta",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.5672002857142857,
              "n_questions_counted": 14
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.5503536428571428,
              "n_questions_counted": 14
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.5465163571428572,
              "n_questions_counted": 14
            },
            {
              "model": "zephyr-7b-beta",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.5355240714285714,
              "n_questions_counted": 14
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.531991,
              "n_questions_counted": 14
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.5025104285714286,
              "n_questions_counted": 14
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.4896292142857143,
              "n_questions_counted": 14
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.4436719285714286,
              "n_questions_counted": 14
            }
          ]
        }
      }
    },
    "Racism \\ Antisemitism in the USA": {
      "questions": {
        "2": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.702641,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.688179,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.765957,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.952108,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.415182,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.463268,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.312605,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.434342,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.489957,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.457922,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.412331,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.382847,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.238417,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.207374,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.62677,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.381078,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.538259,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.567151,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.765755,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.310362,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.557078,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.429982,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.607834,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.381349,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.411977,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.32754,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.281575,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.232768,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.473795,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.167704,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.362998,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.399373,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "56": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.112964,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.1642,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.772497,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.772497,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.765617,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.856472,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.672322,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.839202,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.561552,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.942371,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.464665,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.942949,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.264005,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.33767,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.847541,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.913253,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.100459,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.205784,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.772497,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.772496,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.685974,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.870293,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.656847,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.138636,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.597,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.07241,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.274286,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.765162,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.337699,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.415958,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.08967,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.079192,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "57": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.986606,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.514204,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.947261,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.947261,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.715347,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.882691,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.663372,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.070565,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.575614,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.162288,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.507291,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.862686,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.354892,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.655401,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.606994,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.093125,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.970317,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.385766,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.947216,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.947248,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.560463,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.823112,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.523108,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.129037,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.532366,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.048181,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.169312,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.783421,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.417165,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.615873,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.714934,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.136821,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "58": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.434521,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.747287,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.791161,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.565491,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.358601,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.357622,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.296697,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.429241,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.291507,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.405562,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.207229,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.253862,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.538607,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.353239,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.320353,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.443927,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.373757,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.655932,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.618309,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.474075,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.22266,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.225767,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.279722,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.451636,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.284347,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.357213,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.541661,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.146581,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.469392,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.427167,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.36174,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.469704,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "59": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.935358,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.505427,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.477656,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.314351,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.71683,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.89113,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.667688,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.033833,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.580465,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.124996,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.521113,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.833064,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.329317,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.782908,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.650249,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.086307,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.90856,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.38041,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.311293,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.594148,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.550175,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.798533,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.627789,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.101874,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.535367,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.027305,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.186796,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.570975,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.403833,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.623956,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.871901,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.136101,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "60": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.899372,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.398254,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.005641,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.727245,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.670855,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.926363,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.593064,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.999684,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.51688,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.049035,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.4548,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.851084,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.222961,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.676217,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.58302,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.06147,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.854726,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.286415,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.911646,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.571419,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.514544,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.771793,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.585226,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.104879,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.461408,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.852496,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.090068,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.547899,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.331459,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.551202,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.856107,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.05835,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "61": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.054814,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.664829,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.7737,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.773607,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.787666,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.179443,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.678901,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.247961,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.563403,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.416659,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.651343,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.076159,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.366579,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.988632,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.789575,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.307873,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.117816,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.533127,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.773697,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.77365,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.682742,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.013595,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.651081,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.346075,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.59918,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.179804,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.369433,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.834308,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.420991,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.536082,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.029152,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.306762,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "62": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.446329,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.820669,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.841162,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.6562,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.404206,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.394118,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.322712,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.508601,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.2579,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.527997,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.239121,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.357126,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.418339,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.452405,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.31196,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.470798,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.425992,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.650182,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.787461,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.645653,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.243014,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.28581,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.309696,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.515864,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.241109,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.350585,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.474476,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.29628,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.392608,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.387784,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.35663,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.525844,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "63": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.539108,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.847689,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.74876,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.260359,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.512822,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.508033,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.440437,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.571608,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.358242,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.589516,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.35251,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.444231,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.272285,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.571135,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.431131,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.597871,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.529532,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.749504,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.744233,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.629439,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.33434,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.349994,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.447095,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.626703,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.31332,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.445946,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.663597,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.331391,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.346944,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.387055,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.510655,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.623897,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "64": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.683529,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.115447,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.627171,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.331102,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.619081,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.626428,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.554651,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.708755,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.477152,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.776423,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.434067,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.540606,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.174915,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.691297,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.500802,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.720691,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.673787,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.909766,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.623651,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.323368,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.465351,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.468238,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.555042,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.738633,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.422457,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.565129,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.815058,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.428361,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.271749,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.499923,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.606733,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.732452,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "96": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.231203,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.804285,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.317307,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.406883,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.129279,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.586796,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.665607,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.451551,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.101302,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.620407,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.430709,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.194394,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.544213,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.367094,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.204529,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.491336,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.356329,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.753988,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.317306,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.406883,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.157594,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.569772,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.180939,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.5293,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.161939,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.372097,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.475721,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.474157,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.857241,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.245401,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.193784,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.538205,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "97": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.526781,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.743137,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.091837,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.434103,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.448031,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.543768,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.206005,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.493107,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.405031,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.577,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.144975,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.229223,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.145194,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.326559,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.43203,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.476796,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.627254,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.658606,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.091837,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.413284,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.367592,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.522955,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.710522,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.516523,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.441006,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.362243,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.186553,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.27802,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.337086,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.34669,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.396714,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.503525,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "98": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.442348,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.737461,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.900716,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.125895,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.526342,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.892961,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.291876,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.949079,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.405164,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.844137,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.527868,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.676847,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.222925,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.530151,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.537101,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.939235,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.353193,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.759883,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.900716,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.125896,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.6513,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.909069,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.16769,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.943405,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.574416,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.081571,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.534421,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.751797,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.142546,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.454436,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.598447,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.938182,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "101": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.422514,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.431733,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.951662,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.505538,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.368505,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.360892,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.133764,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.546129,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.189301,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.338467,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.354116,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.599785,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.125827,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.333463,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.4385,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.556012,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.428127,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.416387,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.951662,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.505538,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.293752,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.31045,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.079035,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.386619,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.238564,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.326063,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.392871,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.465043,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.403922,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.307861,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.242506,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.402892,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "102": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.757441,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.834334,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.612903,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.040234,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.730855,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.827472,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.522345,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.887565,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.536412,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.360279,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.743455,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.390305,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.254714,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.375163,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.607597,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.954111,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.776586,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.817117,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.612903,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.040259,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.653091,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.780201,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.45778,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.710427,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.546141,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.74703,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.78356,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.386788,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.041516,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.305923,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.741966,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.794417,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "103": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.465818,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.459629,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.919436,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.433028,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.409853,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.443372,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.152843,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.615333,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.235266,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.297748,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.388318,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.534079,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.116532,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.259728,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.42637,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.57782,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.444621,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.440129,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.919436,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.43301,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.330692,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.397087,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.10228,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.441578,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.234003,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.427399,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.386387,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.418256,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.474817,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.216581,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.317942,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.419881,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "122": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.348464,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.373308,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.180808,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.258382,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.281882,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.395304,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.348404,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.311327,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.311618,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.377849,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.327695,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.625068,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.352298,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.390982,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.271221,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.331663,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.335521,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.360053,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.180808,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.257416,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.318259,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.425161,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.472808,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.307503,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.302077,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.360507,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.187236,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.227234,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.358889,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.416555,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.309488,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.340263,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "123": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.351581,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.384762,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.180805,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.171728,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.274272,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.397426,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.405293,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.313383,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.313502,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.381319,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.340196,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.615812,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.36484,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.399324,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.27547,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.33219,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.338342,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.358329,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.180806,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.275225,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.321919,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.423499,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.51046,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.30739,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.301088,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.35317,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.201689,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.223594,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.367873,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.421999,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.322133,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.336764,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        }
      },
      "summary": {
        "by_model_language_variant": {
          "no_refusal": [
            {
              "model": "c4ai-command-r7b",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.9574907777777777,
              "n_questions_counted": 18
            },
            {
              "model": "gpt-4o-mini",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.815334,
              "n_questions_counted": 18
            },
            {
              "model": "zephyr-7b-beta",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.7630864444444444,
              "n_questions_counted": 18
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.7450703333333333,
              "n_questions_counted": 18
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.7361097222222222,
              "n_questions_counted": 18
            },
            {
              "model": "gpt-4o-mini",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.7170244444444445,
              "n_questions_counted": 18
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.6963088333333334,
              "n_questions_counted": 18
            },
            {
              "model": "c4ai-command-r7b",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.685632888888889,
              "n_questions_counted": 18
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.6338959444444444,
              "n_questions_counted": 18
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.5630681111111111,
              "n_questions_counted": 18
            },
            {
              "model": "zephyr-7b-beta",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.5478451666666666,
              "n_questions_counted": 18
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.5388189999999999,
              "n_questions_counted": 18
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.4539037777777778,
              "n_questions_counted": 18
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.440477,
              "n_questions_counted": 18
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.41676677777777776,
              "n_questions_counted": 18
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.2948255555555555,
              "n_questions_counted": 18
            }
          ],
          "with_refusal": [
            {
              "model": "c4ai-command-r7b",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.8826960555555555,
              "n_questions_counted": 18
            },
            {
              "model": "gpt-4o-mini",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.8610760555555556,
              "n_questions_counted": 18
            },
            {
              "model": "zephyr-7b-beta",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.7634791666666667,
              "n_questions_counted": 18
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.7598572777777778,
              "n_questions_counted": 18
            },
            {
              "model": "gpt-4o-mini",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.6895128888888888,
              "n_questions_counted": 18
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.6809271666666666,
              "n_questions_counted": 18
            },
            {
              "model": "c4ai-command-r7b",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.6751765555555556,
              "n_questions_counted": 18
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.6674833333333333,
              "n_questions_counted": 18
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.6319617222222222,
              "n_questions_counted": 18
            },
            {
              "model": "zephyr-7b-beta",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.6046388888888888,
              "n_questions_counted": 18
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.5090019444444445,
              "n_questions_counted": 18
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.49583077777777773,
              "n_questions_counted": 18
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.49502999999999997,
              "n_questions_counted": 18
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.46267499999999995,
              "n_questions_counted": 18
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.4554313888888889,
              "n_questions_counted": 18
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.38052916666666664,
              "n_questions_counted": 18
            }
          ]
        }
      }
    },
    "Terror": {
      "questions": {
        "0": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.624163,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.478742,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.761036,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.519728,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.361269,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.458259,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.416954,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.40731,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.508464,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.445951,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.31706,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.36036,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.386284,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.090191,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.361809,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.470423,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.553074,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.555676,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.761045,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.553357,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.482775,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.418974,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.413392,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.479528,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.514595,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.560382,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.391293,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.301084,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.092893,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.303245,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.464342,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.487223,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "20": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.307907,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.073139,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.782692,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.782698,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.303214,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.192756,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.190697,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.107178,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.257835,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.183487,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.247914,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.559177,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.235912,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.296731,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.300606,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.110103,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.267249,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.081377,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.782688,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.782698,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.270531,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.112566,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.331808,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.124298,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.248604,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.342454,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.242402,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.137499,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.174312,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.206033,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.287501,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.136708,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "21": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.206904,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.098742,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.632886,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.954793,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.184967,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.29029,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.091877,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.074766,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.146986,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.13915,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.188786,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.43261,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.118983,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.20761,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.19533,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.050096,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.160449,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.083069,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.613122,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.954822,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.166827,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.102242,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.220458,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.041175,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.113716,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.167752,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.208664,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.089178,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.084286,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.279423,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.175414,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.07805,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "24": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.151406,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.023665,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.532344,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.532344,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.09634,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.006098,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.03906,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.001135,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.05848,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.077422,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.031997,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.060629,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.048272,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.110909,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.207694,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.032935,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.161862,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.089071,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.532344,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.532343,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.193031,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.013133,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.085431,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.005065,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.023454,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.016321,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.013077,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.018367,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.061312,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.044936,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.18799,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.001558,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        },
        "55": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.204619,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.179131,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.476241,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.476241,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.148176,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.056413,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.123893,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.038764,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.120233,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.153373,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.011338,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.145338,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.002245,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.214799,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.195388,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.047578,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.171663,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.192934,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.476241,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.47624,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.199809,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.051889,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.175209,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.060768,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.063402,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.060779,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.02002,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.02609,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.111912,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.108042,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.189807,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.052995,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        }
      },
      "summary": {
        "by_model_language_variant": {
          "no_refusal": [
            {
              "model": "gpt-4o-mini",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.6531608,
              "n_questions_counted": 5
            },
            {
              "model": "gpt-4o-mini",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.6370397999999999,
              "n_questions_counted": 5
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.3116228,
              "n_questions_counted": 5
            },
            {
              "model": "c4ai-command-r7b",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.2989998,
              "n_questions_counted": 5
            },
            {
              "model": "zephyr-7b-beta",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.2521654,
              "n_questions_counted": 5
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.2187932,
              "n_questions_counted": 5
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.2183996,
              "n_questions_counted": 5
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.2007632,
              "n_questions_counted": 5
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.19987660000000002,
              "n_questions_counted": 5
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.184048,
              "n_questions_counted": 5
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.17249620000000002,
              "n_questions_counted": 5
            },
            {
              "model": "c4ai-command-r7b",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.1706838,
              "n_questions_counted": 5
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.159419,
              "n_questions_counted": 5
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.1583392,
              "n_questions_counted": 5
            },
            {
              "model": "zephyr-7b-beta",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.142227,
              "n_questions_counted": 5
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.1258306,
              "n_questions_counted": 5
            }
          ],
          "with_refusal": [
            {
              "model": "gpt-4o-mini",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.6598919999999999,
              "n_questions_counted": 5
            },
            {
              "model": "gpt-4o-mini",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.6330880000000001,
              "n_questions_counted": 5
            },
            {
              "model": "c4ai-command-r7b",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.2628594,
              "n_questions_counted": 5
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.2625946,
              "n_questions_counted": 5
            },
            {
              "model": "zephyr-7b-beta",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.2610108,
              "n_questions_counted": 5
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.24525959999999997,
              "n_questions_counted": 5
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.2295376,
              "n_questions_counted": 5
            },
            {
              "model": "c4ai-command-r7b",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.2004254,
              "n_questions_counted": 5
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.19275420000000001,
              "n_questions_counted": 5
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.1883358,
              "n_questions_counted": 5
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.1750912,
              "n_questions_counted": 5
            },
            {
              "model": "zephyr-7b-beta",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.15130680000000002,
              "n_questions_counted": 5
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.14216679999999998,
              "n_questions_counted": 5
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.1397608,
              "n_questions_counted": 5
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.1144436,
              "n_questions_counted": 5
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.10494300000000001,
              "n_questions_counted": 5
            }
          ]
        }
      }
    },
    "US Patriotism": {
      "questions": {
        "65": {
          "comparisons": {
            "no_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.259635,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.305835,
                "source_file": "wd_survey_vs_c4ai-command-r7b_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.078143,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 1.083269,
                "source_file": "wd_survey_vs_gpt-4o-mini_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.240563,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.393038,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.535267,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.368959,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.467082,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.565278,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.771874,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.872488,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.164723,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.288197,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_no_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.339261,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "no_refusal",
                "WD_survey_vs_model": 0.388052,
                "source_file": "wd_survey_vs_zephyr-7b-beta_no_refusal_hebrew_tmp0.7_seed42.json"
              }
            ],
            "with_refusal": [
              {
                "model": "c4ai-command-r7b",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.329267,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "c4ai-command-r7b",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.306776,
                "source_file": "wd_survey_vs_c4ai-command-r7b_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.066856,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "gpt-4o-mini",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.073766,
                "source_file": "wd_survey_vs_gpt-4o-mini_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.288513,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "llama-3-8b-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.264299,
                "source_file": "wd_survey_vs_llama-3-8b-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.327417,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "mistral-7b-v0.3",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.459159,
                "source_file": "wd_survey_vs_mistral-7b-v0.3_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.436339,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-1.5B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 1.059054,
                "source_file": "wd_survey_vs_Qwen2.5-1.5B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.779331,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-3B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.848445,
                "source_file": "wd_survey_vs_Qwen2.5-3B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.213454,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "Qwen2.5-7B-Instruct",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.410275,
                "source_file": "wd_survey_vs_Qwen2.5-7B-Instruct_with_refusal_hebrew_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "english",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.37861,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_english_tmp0.7_seed42.json"
              },
              {
                "model": "zephyr-7b-beta",
                "language": "hebrew",
                "variant": "with_refusal",
                "WD_survey_vs_model": 0.454788,
                "source_file": "wd_survey_vs_zephyr-7b-beta_with_refusal_hebrew_tmp0.7_seed42.json"
              }
            ]
          }
        }
      },
      "summary": {
        "by_model_language_variant": {
          "no_refusal": [
            {
              "model": "gpt-4o-mini",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 1.083269,
              "n_questions_counted": 1
            },
            {
              "model": "gpt-4o-mini",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 1.078143,
              "n_questions_counted": 1
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.872488,
              "n_questions_counted": 1
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.771874,
              "n_questions_counted": 1
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.565278,
              "n_questions_counted": 1
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.535267,
              "n_questions_counted": 1
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.467082,
              "n_questions_counted": 1
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.393038,
              "n_questions_counted": 1
            },
            {
              "model": "zephyr-7b-beta",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.388052,
              "n_questions_counted": 1
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.368959,
              "n_questions_counted": 1
            },
            {
              "model": "zephyr-7b-beta",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.339261,
              "n_questions_counted": 1
            },
            {
              "model": "c4ai-command-r7b",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.305835,
              "n_questions_counted": 1
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "hebrew",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.288197,
              "n_questions_counted": 1
            },
            {
              "model": "c4ai-command-r7b",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.259635,
              "n_questions_counted": 1
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.240563,
              "n_questions_counted": 1
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "english",
              "variant": "no_refusal",
              "avg_WD_over_topic_questions": 0.164723,
              "n_questions_counted": 1
            }
          ],
          "with_refusal": [
            {
              "model": "gpt-4o-mini",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 1.073766,
              "n_questions_counted": 1
            },
            {
              "model": "gpt-4o-mini",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 1.066856,
              "n_questions_counted": 1
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 1.059054,
              "n_questions_counted": 1
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.848445,
              "n_questions_counted": 1
            },
            {
              "model": "Qwen2.5-3B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.779331,
              "n_questions_counted": 1
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.459159,
              "n_questions_counted": 1
            },
            {
              "model": "zephyr-7b-beta",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.454788,
              "n_questions_counted": 1
            },
            {
              "model": "Qwen2.5-1.5B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.436339,
              "n_questions_counted": 1
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.410275,
              "n_questions_counted": 1
            },
            {
              "model": "zephyr-7b-beta",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.37861,
              "n_questions_counted": 1
            },
            {
              "model": "c4ai-command-r7b",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.329267,
              "n_questions_counted": 1
            },
            {
              "model": "mistral-7b-v0.3",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.327417,
              "n_questions_counted": 1
            },
            {
              "model": "c4ai-command-r7b",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.306776,
              "n_questions_counted": 1
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.288513,
              "n_questions_counted": 1
            },
            {
              "model": "llama-3-8b-Instruct",
              "language": "hebrew",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.264299,
              "n_questions_counted": 1
            },
            {
              "model": "Qwen2.5-7B-Instruct",
              "language": "english",
              "variant": "with_refusal",
              "avg_WD_over_topic_questions": 0.213454,
              "n_questions_counted": 1
            }
          ]
        }
      }
    }
  },
  "global_summary": {
    "meta": {
      "files_scanned": 33,
      "files_with_summary_metric": 32
    },
    "overall_average_WD_survey_vs_model_across_files": 0.50054365625,
    "by_model_language_variant": {
      "no_refusal": [
        {
          "model": "gpt-4o-mini",
          "language": "hebrew",
          "variant": "no_refusal",
          "avg_of_file_level_average_WD": 0.949661,
          "n_files": 1
        },
        {
          "model": "gpt-4o-mini",
          "language": "english",
          "variant": "no_refusal",
          "avg_of_file_level_average_WD": 0.808242,
          "n_files": 1
        },
        {
          "model": "Qwen2.5-1.5B-Instruct",
          "language": "hebrew",
          "variant": "no_refusal",
          "avg_of_file_level_average_WD": 0.517173,
          "n_files": 1
        },
        {
          "model": "c4ai-command-r7b",
          "language": "hebrew",
          "variant": "no_refusal",
          "avg_of_file_level_average_WD": 0.516347,
          "n_files": 1
        },
        {
          "model": "Qwen2.5-3B-Instruct",
          "language": "hebrew",
          "variant": "no_refusal",
          "avg_of_file_level_average_WD": 0.490822,
          "n_files": 1
        },
        {
          "model": "mistral-7b-v0.3",
          "language": "hebrew",
          "variant": "no_refusal",
          "avg_of_file_level_average_WD": 0.483938,
          "n_files": 1
        },
        {
          "model": "zephyr-7b-beta",
          "language": "hebrew",
          "variant": "no_refusal",
          "avg_of_file_level_average_WD": 0.48194,
          "n_files": 1
        },
        {
          "model": "llama-3-8b-Instruct",
          "language": "hebrew",
          "variant": "no_refusal",
          "avg_of_file_level_average_WD": 0.478566,
          "n_files": 1
        },
        {
          "model": "c4ai-command-r7b",
          "language": "english",
          "variant": "no_refusal",
          "avg_of_file_level_average_WD": 0.466027,
          "n_files": 1
        },
        {
          "model": "Qwen2.5-7B-Instruct",
          "language": "hebrew",
          "variant": "no_refusal",
          "avg_of_file_level_average_WD": 0.463427,
          "n_files": 1
        },
        {
          "model": "zephyr-7b-beta",
          "language": "english",
          "variant": "no_refusal",
          "avg_of_file_level_average_WD": 0.450282,
          "n_files": 1
        },
        {
          "model": "Qwen2.5-1.5B-Instruct",
          "language": "english",
          "variant": "no_refusal",
          "avg_of_file_level_average_WD": 0.423631,
          "n_files": 1
        },
        {
          "model": "llama-3-8b-Instruct",
          "language": "english",
          "variant": "no_refusal",
          "avg_of_file_level_average_WD": 0.413702,
          "n_files": 1
        },
        {
          "model": "Qwen2.5-3B-Instruct",
          "language": "english",
          "variant": "no_refusal",
          "avg_of_file_level_average_WD": 0.385157,
          "n_files": 1
        },
        {
          "model": "mistral-7b-v0.3",
          "language": "english",
          "variant": "no_refusal",
          "avg_of_file_level_average_WD": 0.367861,
          "n_files": 1
        },
        {
          "model": "Qwen2.5-7B-Instruct",
          "language": "english",
          "variant": "no_refusal",
          "avg_of_file_level_average_WD": 0.322992,
          "n_files": 1
        }
      ],
      "with_refusal": [
        {
          "model": "gpt-4o-mini",
          "language": "hebrew",
          "variant": "with_refusal",
          "avg_of_file_level_average_WD": 0.965205,
          "n_files": 1
        },
        {
          "model": "gpt-4o-mini",
          "language": "english",
          "variant": "with_refusal",
          "avg_of_file_level_average_WD": 0.805327,
          "n_files": 1
        },
        {
          "model": "Qwen2.5-1.5B-Instruct",
          "language": "hebrew",
          "variant": "with_refusal",
          "avg_of_file_level_average_WD": 0.539428,
          "n_files": 1
        },
        {
          "model": "c4ai-command-r7b",
          "language": "hebrew",
          "variant": "with_refusal",
          "avg_of_file_level_average_WD": 0.505527,
          "n_files": 1
        },
        {
          "model": "mistral-7b-v0.3",
          "language": "hebrew",
          "variant": "with_refusal",
          "avg_of_file_level_average_WD": 0.478594,
          "n_files": 1
        },
        {
          "model": "zephyr-7b-beta",
          "language": "hebrew",
          "variant": "with_refusal",
          "avg_of_file_level_average_WD": 0.477441,
          "n_files": 1
        },
        {
          "model": "llama-3-8b-Instruct",
          "language": "hebrew",
          "variant": "with_refusal",
          "avg_of_file_level_average_WD": 0.457418,
          "n_files": 1
        },
        {
          "model": "c4ai-command-r7b",
          "language": "english",
          "variant": "with_refusal",
          "avg_of_file_level_average_WD": 0.450981,
          "n_files": 1
        },
        {
          "model": "Qwen2.5-3B-Instruct",
          "language": "hebrew",
          "variant": "with_refusal",
          "avg_of_file_level_average_WD": 0.442739,
          "n_files": 1
        },
        {
          "model": "mistral-7b-v0.3",
          "language": "english",
          "variant": "with_refusal",
          "avg_of_file_level_average_WD": 0.430044,
          "n_files": 1
        },
        {
          "model": "Qwen2.5-7B-Instruct",
          "language": "hebrew",
          "variant": "with_refusal",
          "avg_of_file_level_average_WD": 0.42882,
          "n_files": 1
        },
        {
          "model": "llama-3-8b-Instruct",
          "language": "english",
          "variant": "with_refusal",
          "avg_of_file_level_average_WD": 0.422111,
          "n_files": 1
        },
        {
          "model": "Qwen2.5-1.5B-Instruct",
          "language": "english",
          "variant": "with_refusal",
          "avg_of_file_level_average_WD": 0.410997,
          "n_files": 1
        },
        {
          "model": "Qwen2.5-3B-Instruct",
          "language": "english",
          "variant": "with_refusal",
          "avg_of_file_level_average_WD": 0.410184,
          "n_files": 1
        },
        {
          "model": "zephyr-7b-beta",
          "language": "english",
          "variant": "with_refusal",
          "avg_of_file_level_average_WD": 0.409481,
          "n_files": 1
        },
        {
          "model": "Qwen2.5-7B-Instruct",
          "language": "english",
          "variant": "with_refusal",
          "avg_of_file_level_average_WD": 0.363332,
          "n_files": 1
        }
      ]
    }
  }
}